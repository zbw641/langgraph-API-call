# -*- coding: utf-8 -*-
"""
@description: åŸºäº LangSmith çš„ RAG é—®ç­”ç³»ç»Ÿè¯„ä¼°ï¼ˆ10åˆ†åˆ¶ç‰ˆæœ¬ï¼‰
@author: AI Assistant
@version: 2.0 (æ”¹ä¸º10åˆ†åˆ¶åº¦)
"""
import os
import re
import csv
import uuid
from langsmith import wrappers, Client
import openai
from loguru import logger
from source.graph import build_agent
from source.agent import initialize_rag
import numpy as np

# ğŸ”¥ æ”¹ç”¨ similarities åº“ï¼ˆä¸å‚è€ƒä»£ç ä¸€è‡´ï¼‰
from similarities import BertSimilarity
from dotenv import load_dotenv

load_dotenv()
langsmith_api = os.getenv("LAPI")
print(langsmith_api)
# ============================================
# 1. é…ç½® LangSmith ç¯å¢ƒå˜é‡
# ============================================
os.environ['LANGSMITH_TRACING'] = "true"
os.environ['LANGSMITH_API_KEY'] = langsmith_api
os.environ['LANGSMITH_ENDPOINT'] = "https://api.smith.langchain.com"
os.environ['LANGSMITH_PROJECT'] = "rag-qa-semantic-eval"

# ============================================
# 2. åˆå§‹åŒ–
# ============================================
client = Client()
openai_client = wrappers.wrap_openai(openai.OpenAI(
    api_key="1",
    base_url="http://127.0.0.1:1234/v1",
))

# ğŸ”¥ å…¨å±€å˜é‡ï¼šembedding æ¨¡å‹
embedding_model = None

# ============================================
# 3. æ•°æ®é›†åˆ›å»º
# ============================================
DATASET_NAME = "RAG-QA-Semantic-Dataset"
CSV_FILE = "qa_test_set.csv"


def create_dataset_from_csv():
    """ä» CSV æ–‡ä»¶åˆ›å»º LangSmith æ•°æ®é›†"""
    logger.info(f"æ­£åœ¨ä» {CSV_FILE} åˆ›å»ºæ•°æ®é›†...")

    try:
        existing_dataset = client.read_dataset(dataset_name=DATASET_NAME)
        logger.info(f"æ•°æ®é›† '{DATASET_NAME}' å·²å­˜åœ¨ï¼Œå°†åˆ é™¤åé‡æ–°åˆ›å»º")
        client.delete_dataset(dataset_id=existing_dataset.id)
    except Exception:
        logger.info(f"æ•°æ®é›† '{DATASET_NAME}' ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ•°æ®é›†")

    dataset = client.create_dataset(
        dataset_name=DATASET_NAME,
        description="RAG é—®ç­”ç³»ç»Ÿè¯­ä¹‰ç›¸ä¼¼åº¦æµ‹è¯•æ•°æ®é›†"
    )

    with open(CSV_FILE, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            client.create_example(
                dataset_id=dataset.id,
                inputs={"question": row["question"]},
                outputs={"answer": row["answer"]}
            )

    logger.info(f"âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ: {DATASET_NAME}")
    return dataset


# ============================================
# 4. åˆå§‹åŒ– RAG ç³»ç»Ÿ + Embedding æ¨¡å‹
# ============================================
def initialize_rag_system():
    """åˆå§‹åŒ– RAG æ£€ç´¢å™¨"""
    global embedding_model

    logger.info("æ­£åœ¨åˆå§‹åŒ– RAG ç³»ç»Ÿ...")

    data_dir = "data/"
    data_files = []

    if os.path.exists(data_dir) and os.path.isdir(data_dir):
        for filename in os.listdir(data_dir):
            file_path = os.path.join(data_dir, filename)
            if os.path.isfile(file_path) and not filename.startswith('.'):
                data_files.append(file_path)
        logger.info(f"æ‰¾åˆ° {len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    else:
        logger.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False

    if not data_files:
        logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶")
        return False

    success = initialize_rag(
        corpus_files=data_files,
        chunk_size=250,
        num_expand_context=0,
        chunk_overlap=100,
        similarity_top_k=10,
        use_rerank=False
    )

    if success:
        logger.info("âœ… RAG ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    else:
        logger.error("âŒ RAG ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
        return False

    # ğŸ”¥ ä½¿ç”¨ BertSimilarity åŠ è½½ embedding æ¨¡å‹ï¼ˆä¸å‚è€ƒä»£ç ä¸€è‡´ï¼‰
    logger.info("æ­£åœ¨åŠ è½½ embedding æ¨¡å‹: shibing624/text2vec-base-multilingual")
    try:
        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ BertSimilarityï¼ŒæŒ‡å®šè®¾å¤‡
        import torch
        device = torch.device(0) if torch.cuda.is_available() else torch.device('cpu')

        embedding_model = BertSimilarity(
            model_name_or_path="shibing624/text2vec-base-multilingual",
            device=device
        )
        logger.info(f"âœ… Embedding æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {device})")
    except Exception as e:
        logger.error(f"âŒ Embedding æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

    return True


# ============================================
# 5. è¯„ä¼°å™¨ï¼šæ­£ç¡®æ€§ + è¯­ä¹‰ç›¸ä¼¼åº¦
# ============================================
EVAL_INSTRUCTIONS = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¯„åˆ†ä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£è¯„ä¼°é—®ç­”ç³»ç»Ÿçš„å›ç­”è´¨é‡ã€‚"


def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> float:
    """
    ğŸ”¥ è¯„ä¼°ç­”æ¡ˆçš„æ­£ç¡®æ€§ï¼ˆä½¿ç”¨ LLMï¼‰- 10åˆ†åˆ¶
    è¿”å›: 0.0-1.0
    """
    user_content = f"""ä½ æ­£åœ¨è¯„ä¼°ä»¥ä¸‹é—®é¢˜çš„ç­”æ¡ˆè´¨é‡ã€‚

é—®é¢˜ï¼š
{inputs['question']}

æ ‡å‡†ç­”æ¡ˆï¼š
{reference_outputs['answer']}

å¾…è¯„ä¼°ç­”æ¡ˆï¼š
{outputs['response']}

è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†è¯„åˆ†ï¼ˆ0-10ï¼‰ï¼š
- 10ï¼šå®Œç¾ç­”æ¡ˆï¼Œå®Œå…¨æ­£ç¡®ä¸”è¡¨è¿°æ¸…æ™°
- 9ï¼šä¼˜ç§€ç­”æ¡ˆï¼ŒåŒ…å«æ‰€æœ‰å…³é”®ä¿¡æ¯ï¼Œç•¥æœ‰ç‘•ç–µ
- 8ï¼šè‰¯å¥½ç­”æ¡ˆï¼ŒåŒ…å«æ‰€æœ‰å…³é”®ä¿¡æ¯ï¼Œä½†è¡¨è¿°ä¸å¤Ÿç²¾å‡†
- 7ï¼šè¾ƒå¥½ç­”æ¡ˆï¼ŒåŒ…å«å¤§éƒ¨åˆ†å…³é”®ä¿¡æ¯ï¼Œæœ‰å°‘é‡é—æ¼
- 6ï¼šåŠæ ¼ç­”æ¡ˆï¼ŒåŒ…å«ä¸»è¦å…³é”®ä¿¡æ¯ï¼Œä½†ç¼ºå¤±é‡è¦ç»†èŠ‚
- 5ï¼šåŸºæœ¬ç­”æ¡ˆï¼ŒåŒ…å«éƒ¨åˆ†å…³é”®ä¿¡æ¯ï¼Œé—æ¼è¾ƒå¤š
- 4ï¼šè¾ƒå·®ç­”æ¡ˆï¼Œä»…åŒ…å«å°‘é‡å…³é”®ä¿¡æ¯
- 3ï¼šå·®ç­”æ¡ˆï¼Œå¤§éƒ¨åˆ†å†…å®¹é”™è¯¯æˆ–ä¸ç›¸å…³
- 2ï¼šå¾ˆå·®ç­”æ¡ˆï¼Œå‡ ä¹å®Œå…¨é”™è¯¯
- 1ï¼šæå·®ç­”æ¡ˆï¼Œç­”éæ‰€é—®
- 0ï¼šå®Œå…¨é”™è¯¯æˆ–æ— æ„ä¹‰

è¯·ç›´æ¥è¾“å‡ºåˆ†æ•°ï¼ˆåªè¾“å‡ºæ•°å­—ï¼Œä¾‹å¦‚ï¼š8ï¼‰
åˆ†æ•°ï¼š"""

    try:
        response = openai_client.chat.completions.create(
            model="qwen3/qwen3-8b",
            temperature=0,
            messages=[
                {"role": "system", "content": EVAL_INSTRUCTIONS},
                {"role": "user", "content": user_content},
            ],
        ).choices[0].message.content

        # ğŸ”¥ ä¿®æ”¹æ­£åˆ™è¡¨è¾¾å¼ï¼Œèƒ½åŒ¹é… "9"ã€"9åˆ†"ã€"10"ã€"10åˆ†" ç­‰æ ¼å¼
        match = re.search(r'(10|[0-9])(?:åˆ†)?', response)
        if match:
            score = int(match.group(1))
            score = min(max(score, 0), 10)
            normalized_score = score / 10.0
            logger.info(f"âœ… æ­£ç¡®æ€§è¯„åˆ†: {score}/10 â†’ {normalized_score:.3f} (åŸå§‹å“åº”: {response.strip()})")
            return normalized_score
        else:
            logger.warning(f"âš ï¸  æ— æ³•æå–åˆ†æ•°ï¼ŒåŸå§‹å“åº”: {response}")
            return 0.0
    except Exception as e:
        logger.error(f"âŒ è¯„ä¼°æ­£ç¡®æ€§æ—¶å‡ºé”™: {e}")
        return 0.0


def semantic_similarity(outputs: dict, reference_outputs: dict) -> float:
    """
    ğŸ”¥ è¯„ä¼°è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ BertSimilarityï¼‰
    è¿”å›: 0.0-1.0 çš„ç›¸ä¼¼åº¦åˆ†æ•°
    """
    try:
        # æå–æ–‡æœ¬
        response_text = outputs["response"]
        reference_text = reference_outputs["answer"]

        if embedding_model is None:
            logger.error("âŒ Embedding æ¨¡å‹æœªåˆå§‹åŒ–")
            return 0.0

        # ğŸ”¥ ä½¿ç”¨ BertSimilarity çš„ similarity æ–¹æ³•
        # æ³¨æ„ï¼šBertSimilarity è¿”å›çš„æ˜¯ç›¸ä¼¼åº¦åˆ†æ•°ï¼ŒèŒƒå›´é€šå¸¸åœ¨ [-1, 1] æˆ– [0, 1]
        similarity_score = embedding_model.similarity(response_text, reference_text)

        # ğŸ”¥ å¦‚æœè¿”å›çš„æ˜¯å•ä¸ªå€¼ï¼Œç›´æ¥ä½¿ç”¨
        if isinstance(similarity_score, (int, float)):
            similarity = float(similarity_score)
        # ğŸ”¥ å¦‚æœè¿”å›çš„æ˜¯æ•°ç»„/tensorï¼Œå–ç¬¬ä¸€ä¸ªå€¼
        elif hasattr(similarity_score, '__iter__'):
            similarity = float(list(similarity_score)[0])
        else:
            logger.warning(f"âš ï¸ æœªçŸ¥çš„ç›¸ä¼¼åº¦è¿”å›ç±»å‹: {type(similarity_score)}")
            similarity = 0.0

        # ç¡®ä¿åœ¨ 0-1 èŒƒå›´å†…ï¼ˆå¦‚æœåŸå§‹èŒƒå›´æ˜¯ [-1, 1]ï¼Œéœ€è¦è½¬æ¢ï¼‰
        if similarity < 0:
            similarity = (similarity + 1) / 2  # ä» [-1, 1] è½¬æ¢åˆ° [0, 1]

        similarity = float(np.clip(similarity, 0.0, 1.0))

        logger.info(f"ğŸ“Š è¯­ä¹‰ç›¸ä¼¼åº¦: {similarity:.3f}")
        logger.debug(f"   å›ç­”: {response_text[:50]}...")
        logger.debug(f"   å‚è€ƒ: {reference_text[:50]}...")

        return similarity

    except Exception as e:
        logger.error(f"âŒ è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦æ—¶å‡ºé”™: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 0.0


# ============================================
# 6. ç›®æ ‡å‡½æ•°
# ============================================
def rag_target(inputs: dict) -> dict:
    """RAG ç³»ç»Ÿçš„é¢„æµ‹å‡½æ•°"""
    question = inputs["question"]

    try:
        thread_id = str(uuid.uuid4())
        logger.info(f"ğŸ“ å¤„ç†é—®é¢˜: {question}")

        # è°ƒç”¨ä½ çš„ RAG ç³»ç»Ÿ
        answer = build_agent(query=question, thread_id=thread_id)

        # æ£€æŸ¥è¿”å›å€¼
        if answer is None:
            logger.warning("âš ï¸  build_agent è¿”å› None")
            return {"response": "ç³»ç»Ÿæœªè¿”å›ç­”æ¡ˆ"}

        if not isinstance(answer, str):
            logger.warning(f"âš ï¸  è¿”å›å€¼ç±»å‹å¼‚å¸¸: {type(answer)}")
            answer = str(answer)

        if answer.strip() == "":
            logger.warning("âš ï¸  è¿”å›ç©ºå­—ç¬¦ä¸²")
            return {"response": "ç³»ç»Ÿè¿”å›ç©ºç­”æ¡ˆ"}

        logger.info(f"âœ… è·å¾—ç­”æ¡ˆ (é•¿åº¦: {len(answer)})")
        return {"response": answer}

    except Exception as e:
        logger.error(f"âŒ è°ƒç”¨ build_agent æ—¶å‡ºé”™: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {"response": f"ç³»ç»Ÿé”™è¯¯: {str(e)}"}


# ============================================
# 7. è¿è¡Œè¯„ä¼°å®éªŒ
# ============================================
def run_evaluation():
    """è¿è¡Œå®Œæ•´çš„è¯„ä¼°æµç¨‹"""
    logger.info("=" * 60)
    logger.info("å¼€å§‹ RAG é—®ç­”ç³»ç»Ÿè¯„ä¼°ï¼ˆ10åˆ†åˆ¶ï¼‰")
    logger.info("=" * 60)

    # æ­¥éª¤ 1: åˆå§‹åŒ– RAG ç³»ç»Ÿ + Embedding æ¨¡å‹
    if not initialize_rag_system():
        logger.error("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡ºè¯„ä¼°")
        return

    # æ­¥éª¤ 2: åˆ›å»ºæ•°æ®é›†
    dataset = create_dataset_from_csv()

    # æ­¥éª¤ 3: è¿è¡Œè¯„ä¼°
    logger.info(f"å¼€å§‹è¯„ä¼°å®éªŒ...")
    logger.info(f"è¯„ä¼°æŒ‡æ ‡:")
    logger.info(f"  1. correctness: LLM è¯„ä¼°ç­”æ¡ˆæ­£ç¡®æ€§ (0-10åˆ†åˆ¶ï¼Œå½’ä¸€åŒ–åˆ°0-1)")
    logger.info(f"  2. semantic_similarity: Embedding ç›¸ä¼¼åº¦ (0-1)")

    experiment_results = client.evaluate(
        rag_target,
        data=DATASET_NAME,
        evaluators=[correctness, semantic_similarity],
        experiment_prefix="rag-qa-system",
        description="RAG é—®ç­”ç³»ç»Ÿè¯„ä¼°: æ­£ç¡®æ€§(10åˆ†åˆ¶) + è¯­ä¹‰ç›¸ä¼¼åº¦",
        max_concurrency=1,
    )

    # æ­¥éª¤ 4: è¾“å‡ºç»“æœæ‘˜è¦
    logger.info("=" * 60)
    logger.info("è¯„ä¼°å®Œæˆï¼")
    logger.info("=" * 60)
    logger.info(f"å®éªŒåç§°: {experiment_results.experiment_name}")
    logger.info(f"æ•°æ®é›†: {DATASET_NAME}")
    logger.info(f"æŸ¥çœ‹è¯¦ç»†ç»“æœ: https://smith.langchain.com")
    logger.info("=" * 60)

    return experiment_results


# ============================================
# 8. ä¸»å‡½æ•°
# ============================================
def main():
    """ä¸»å‡½æ•°"""
    try:
        results = run_evaluation()

        if results:
            logger.info("âœ… è¯„ä¼°æˆåŠŸå®Œæˆ")
            logger.info(f"ğŸ“Š å®éªŒID: {results.experiment_name}")
        else:
            logger.error("âŒ è¯„ä¼°å¤±è´¥")

    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­è¯„ä¼°")
    except Exception as e:
        logger.error(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        logger.error(traceback.format_exc())


if __name__ == '__main__':
    main()